{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77584431-105a-4336-af04-6a071ebf9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 11:44:04.278416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../../src\")\n",
    "\n",
    "# from resnet50.resnets_utils import *\n",
    "\n",
    "import h5py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9660bc-fe43-4f36-b74a-5498800229fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    ## Second component of main path (≈3 lines)\n",
    "    ## Set the padding = 'same'\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X) \n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    ## Set the padding = 'valid'\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X) \n",
    "    \n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)  \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1d7203-e34f-4e5f-ae34-3ae664eef72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, s = 2, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    ## Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    \n",
    "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
    "\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8b1f64-79e8-4da2-b00a-8af809627020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: ResNet50\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3)):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Use the instructions above in order to implement all of the Stages below\n",
    "    # Make sure you don't miss adding any required parameter\n",
    "    \n",
    "    ## Stage 3 (≈4 lines)\n",
    "    # `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    \n",
    "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    \n",
    "    # the 5 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    \n",
    "    # the 2 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D()(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "229ff11e-dd10-4e8f-9daf-779bcf379b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 2612\n",
      "Number of testing examples: m_test = 327\n",
      "train_set_x shape: (2612, 64, 64, 3)\n",
      "train_set_y shape: (2612,)\n",
      "test_set_x shape: (327, 64, 64, 3)\n",
      "test_set_y shape: (327,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"../../EIDSeg_Dataset/cache/eidseg_64x64_binary_any.h5\", \"r\") as f:\n",
    "    X_train_org = f[\"X_train\"][:]\n",
    "    Y_train_org = f[\"Y_train\"][:]\n",
    "    X_test_org  = f[\"X_test\"][:]\n",
    "    Y_test_org  = f[\"Y_test\"][:]\n",
    "\n",
    "Y_train = Y_train_org.reshape(-1)\n",
    "Y_test  = Y_test_org.reshape(-1)\n",
    "\n",
    "X_train = X_train_org / 255.0\n",
    "X_test  = X_test_org / 255.0\n",
    "\n",
    "m_train = Y_train.shape[0]\n",
    "m_test = Y_test.shape[0]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"train_set_x shape: \" + str(X_train.shape))\n",
    "print (\"train_set_y shape: \" + str(Y_train.shape))\n",
    "print (\"test_set_x shape: \" + str(X_test.shape))\n",
    "print (\"test_set_y shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a9f0e6-52d2-47fb-9bf6-6cd915dd020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positives: 1847\n",
      "Train negatives: 765\n",
      "Test positives: 242\n",
      "Test negatives: 85\n"
     ]
    }
   ],
   "source": [
    "print(\"Train positives:\", np.sum(Y_train))\n",
    "print(\"Train negatives:\", Y_train.shape[0] - np.sum(Y_train))\n",
    "\n",
    "print(\"Test positives:\", np.sum(Y_test))\n",
    "print(\"Test negatives:\", Y_test.shape[0] - np.sum(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a7c309-19c5-4606-9df8-cce249ca77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = 765\n",
    "pos = 1847\n",
    "total = neg + pos\n",
    "\n",
    "weight_for_0 = total / (2 * neg)\n",
    "weight_for_1 = total / (2 * pos)\n",
    "\n",
    "class_weight = {\n",
    "    0: weight_for_0,  # not damaged\n",
    "    1: weight_for_1   # damaged\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fe08f-ab24-4bb3-8e33-a3461fe4e032",
   "metadata": {},
   "source": [
    "## model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a581d6f-350d-4681-87d7-c4d0f040ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc1dc4-99ea-41be-b88a-7c05f42625b2",
   "metadata": {},
   "source": [
    "## rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e7d63a-6039-47e8-8bba-5297e6306baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8a065c-c633-4250-b3c6-74e6faeb98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m326/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5140 - auc: 0.5091 - loss: 1.3458 - precision: 0.7139 - recall: 0.5156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 11:47:09.742192: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-02-07 11:47:11.344733: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 111ms/step - accuracy: 0.5042 - auc: 0.5017 - loss: 1.1074 - precision: 0.7054 - recall: 0.5133\n",
      "Epoch 2/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5306 - auc: 0.5254 - loss: 0.8137 - precision: 0.7248 - recall: 0.5420\n",
      "Epoch 3/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - accuracy: 0.5145 - auc: 0.5329 - loss: 0.8327 - precision: 0.7215 - recall: 0.5106\n",
      "Epoch 4/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - accuracy: 0.5103 - auc: 0.5225 - loss: 0.8102 - precision: 0.7258 - recall: 0.4943\n",
      "Epoch 5/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - accuracy: 0.5034 - auc: 0.5273 - loss: 0.7860 - precision: 0.7284 - recall: 0.4748\n",
      "Epoch 6/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5203 - auc: 0.5320 - loss: 0.7557 - precision: 0.7309 - recall: 0.5089\n",
      "Epoch 7/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5329 - auc: 0.5401 - loss: 0.7439 - precision: 0.7251 - recall: 0.5468\n",
      "Epoch 8/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - accuracy: 0.5360 - auc: 0.5351 - loss: 0.7477 - precision: 0.7279 - recall: 0.5490\n",
      "Epoch 9/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - accuracy: 0.5287 - auc: 0.5410 - loss: 0.7272 - precision: 0.7337 - recall: 0.5236\n",
      "Epoch 10/10\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5616 - auc: 0.5563 - loss: 0.7245 - precision: 0.7411 - recall: 0.5842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x765e709b3430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 8,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a2b368-442d-4ad0-9308-f184149a0b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5535 - auc: 0.6136 - loss: 2.4677 - precision: 0.7892 - recall: 0.5413\n",
      "Loss = 2.4676549434661865\n",
      "Test Accuracy = 0.5535168051719666\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde16ae-e8cf-40af-9946-87475b4cf42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache(\"../../EIDSeg_Dataset/cache/train_binary_any.tfds\")\n",
    "test_ds  = test_ds.cache(\"../../EIDSeg_Dataset/cache/test_binary_any.tfds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
