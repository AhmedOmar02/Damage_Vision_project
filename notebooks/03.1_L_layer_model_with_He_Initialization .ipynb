{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f3ad7-671e-4970-bcb3-b248a1c81cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn_structure import *\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from Load_data.xml_utils import parse_cvat_xml_all_labels, label_Y_binary\n",
    "from Load_data.data_loader import load_and_resize_images, build_label_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d866d7-f0d0-4c28-a7cf-c03fcdb53f9f",
   "metadata": {},
   "source": [
    "## prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482b487-8f12-4fb4-8db3-088406fb05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_XML = \"../EIDSeg_Dataset/data/train/train.xml\"\n",
    "TEST_XML = \"../EIDSeg_Dataset/data/test/test.xml\"\n",
    "TRAIN_IMAGES = \"../EIDSeg_Dataset/data/train/images/default\"\n",
    "TEST_IMAGES = \"../EIDSeg_Dataset/data/test/images/default\"\n",
    "\n",
    "IMAGE_SIZE = (64, 64)\n",
    "NUM_ITER = 2000\n",
    "\n",
    "\n",
    "\n",
    "labels_train_raw = parse_cvat_xml_all_labels(TRAIN_XML)\n",
    "labels_test_raw = parse_cvat_xml_all_labels(TEST_XML)\n",
    "\n",
    "Y_train_map = label_Y_binary(labels_train_raw)\n",
    "Y_test_map = label_Y_binary(labels_test_raw)\n",
    "\n",
    "X_train_org, ordered_train = load_and_resize_images(TRAIN_IMAGES, size=IMAGE_SIZE)\n",
    "X_test_org, ordered_test = load_and_resize_images(TEST_IMAGES, size=IMAGE_SIZE)\n",
    "\n",
    "Y_train_org = build_label_array(ordered_train, Y_train_map)\n",
    "Y_test_org = build_label_array(ordered_test, Y_test_map)\n",
    "\n",
    "train_x = X_train_org.reshape(X_train_org.shape[0], -1).T\n",
    "test_x = X_test_org.reshape(X_test_org.shape[0], -1).T\n",
    "\n",
    "print(train_x.shape, Y_train_org.shape)\n",
    "print(test_x.shape, Y_test_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1502b8-b4e9-4b40-bc62-cf885d645132",
   "metadata": {},
   "source": [
    "## L-layer Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b91c2-5fde-4763-8b18-762c692907f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [12288, 64, , 5, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e01ee3-f748-4d61-81aa-4539d5f61f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "        \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "                \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL,Y)\n",
    "            \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        # Update parameters.\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                        \n",
    "        # Print the cost every 100 iterations and for the last iteration\n",
    "        if print_cost and (i % 100 == 0 or i == num_iterations - 1):\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bee3a3-d8b8-44e7-81b4-4c78633028e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1] \n",
    "parameters, costs = L_layer_model(train_x, Y_train_org, layers_dims,learning_rate = 0.008, num_iterations = 3500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dce65-6836-4d59-86b1-3a13752cf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = predict(train_x, Y_train_org, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1e70e-835d-4248-bb71-c43abdf918c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = predict(test_x, Y_test_org, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafb582-2ddf-4fa9-9a34-d978f819e590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
