{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b3844f-830f-43b3-94bb-170667d966f5",
   "metadata": {},
   "source": [
    "## Optimized Model: Rethinking the Pipeline\n",
    "\n",
    "In the previous notebooks, I implemented multiple models of increasing complexity, ranging from logistic regression to deeper neural networks. While these experiments were valuable for understanding core concepts in machine learning and deep learning, the resulting performance remained relatively low and inconsistent.\n",
    "\n",
    "After analyzing the results more carefully, it became clear that the limitation was not only related to model architecture or optimization techniques, but also to **how the data was labeled and interpreted**.\n",
    "\n",
    "### Identified Issue with Data Labeling\n",
    "\n",
    "In the earlier approach, an image was classified as *damaged* if **any single polygon** within the image was labeled as `D_Building` or `Debris`. This means that even a small, localized damaged region could cause the entire image to be labeled as damaged.  \n",
    "Such a strategy likely introduces noise and label ambiguity, especially for images that are largely intact but contain minor damage.\n",
    "\n",
    "This coarse labeling scheme may prevent the model from learning meaningful visual patterns related to *overall structural damage*, which is the core objective of this project.\n",
    "\n",
    "### Objective of This Notebook\n",
    "\n",
    "In this notebook, I aim to build the **most optimized model so far**, not only by:\n",
    "- improving model architecture,\n",
    "- applying better initialization, regularization, and optimization techniques,\n",
    "\n",
    "but also by **revisiting and refining the data labeling strategy itself**.\n",
    "\n",
    "By aligning the labels more closely with the true semantic meaning of structural damage, the goal is to provide the model with cleaner supervision and enable more reliable learning.\n",
    "\n",
    "This step marks a transition from experimenting with models to **systematically improving the full machine learning pipeline**, from data understanding to final evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e76b5-52c2-4c6a-b0cb-e65bad887e86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parsing the XML file \n",
    "the code checks the area of the polygon and if classify it accourding to its portion of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae27b1-943d-4ae1-9265-cfbed5fd3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put at top of the cell\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, Tuple, List\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def polygon_area(coords: List[Tuple[float, float]]) -> float:\n",
    "    \"\"\"Compute polygon area using the shoelace formula.\n",
    "    coords: list of (x, y) tuples in vertex order (clockwise or ccw).\n",
    "    \"\"\"\n",
    "    if len(coords) < 3:\n",
    "        return 0.0\n",
    "    x = np.array([p[0] for p in coords], dtype=float)\n",
    "    y = np.array([p[1] for p in coords], dtype=float)\n",
    "    # use roll(-1) to get x_i * y_{i+1}\n",
    "    return 0.5 * abs(np.dot(x, np.roll(y, -1)) - np.dot(y, np.roll(x, -1)))\n",
    "\n",
    "\n",
    "def parse_destroyed_with_size_check(path: str, min_coverage: float = 0.05) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Return {basename(filename): 0/1} where 1 means the image contains at least\n",
    "    one polygon labeled as destroyed and that polygon covers >= min_coverage of image area.\n",
    "\n",
    "    - path: xml annotation file path\n",
    "    - min_coverage: fraction of image area (0..1), e.g. 0.05 -> 5%\n",
    "    \"\"\"\n",
    "    DESTROYED_LABELS = {\"D_Building\", \"Debris\"}\n",
    "    result: Dict[str, int] = {}\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(path)\n",
    "    except ET.ParseError as e:\n",
    "        raise RuntimeError(f\"Failed to parse XML {path}: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        raise RuntimeError(f\"XML file not found: {path}\")\n",
    "\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for image in root.findall(\".//image\"):\n",
    "        filename = image.get(\"name\")\n",
    "        if not filename:\n",
    "            continue\n",
    "        # normalize to basename so it matches files in your images folder\n",
    "        filename_key = os.path.basename(filename)\n",
    "\n",
    "        # get image size (some annotations may store width/height as attributes)\n",
    "        try:\n",
    "            width = int(image.get(\"width\", 0))\n",
    "            height = int(image.get(\"height\", 0))\n",
    "        except ValueError:\n",
    "            width = 0\n",
    "            height = 0\n",
    "        image_area = float(width * height)\n",
    "\n",
    "        # if size missing, try to read size from a nested tag or skip\n",
    "        if image_area == 0:\n",
    "            # fallback: mark as not destroyed (or optionally skip)\n",
    "            result[filename_key] = 0\n",
    "            continue\n",
    "\n",
    "        is_destroyed = False\n",
    "\n",
    "        for polygon in image.findall(\"polygon\"):\n",
    "            label = polygon.get(\"label\")\n",
    "            points = polygon.get(\"points\")\n",
    "\n",
    "            if not label or not points:\n",
    "                continue\n",
    "            if label not in DESTROYED_LABELS:\n",
    "                continue\n",
    "\n",
    "            # Flexible parsing of points:\n",
    "            # common formats: \"x1,y1;x2,y2;...\" or \"x1,y1 x2,y2 ...\" or \"x1,y1;x2,y2;\"\n",
    "            pts_str = points.strip()\n",
    "            if \";\" in pts_str:\n",
    "                raw_pts = pts_str.split(\";\")\n",
    "            else:\n",
    "                raw_pts = pts_str.split()  # split on whitespace\n",
    "\n",
    "            coords = []\n",
    "            for p in raw_pts:\n",
    "                p = p.strip()\n",
    "                if not p:\n",
    "                    continue\n",
    "                # support \"x,y\" or \"x,y,\" etc.\n",
    "                if \",\" not in p:\n",
    "                    # unexpected format\n",
    "                    coords = []\n",
    "                    break\n",
    "                try:\n",
    "                    x_str, y_str = p.split(\",\")[:2]\n",
    "                    coords.append((float(x_str), float(y_str)))\n",
    "                except Exception:\n",
    "                    coords = []\n",
    "                    break\n",
    "\n",
    "            if not coords:\n",
    "                continue\n",
    "\n",
    "            poly_area = polygon_area(coords)\n",
    "            coverage = poly_area / image_area\n",
    "\n",
    "            if coverage >= min_coverage:\n",
    "                is_destroyed = True\n",
    "                break\n",
    "\n",
    "        result[filename_key] = int(is_destroyed)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826edf73-63a3-4e9e-818c-968e05beccb4",
   "metadata": {},
   "source": [
    "# Preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a878f14-ca9b-4775-9e4e-e8f397de9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize_images(images_folder: str, target_size: Tuple[int, int] = (64, 64)):\n",
    "    \"\"\"\n",
    "    Loads image files, resizes to target_size (width, height), normalizes pixels to [0,1].\n",
    "    Returns:\n",
    "      X: numpy array of shape (n_images, height, width, 3)\n",
    "      ordered_filenames: list of basenames corresponding to rows in X\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    ordered_filenames = []\n",
    "\n",
    "    for filename in sorted(os.listdir(images_folder)):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(images_folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Cannot read {filename}, skipping.\")\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # cv2.resize expects (width, height) as tuple (w,h) for target size -> (w,h)\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            img_resized = img_resized.astype(np.float32) / 255.0\n",
    "\n",
    "            X.append(img_resized)\n",
    "            ordered_filenames.append(filename)\n",
    "\n",
    "    X = np.array(X)\n",
    "    print(\"Final X shape:\", X.shape)\n",
    "    return X, ordered_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2731a-ff51-4c42-af82-e35eaaf26b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_label_array(ordered_filenames: List[str], labels_dict: Dict[str, int], default_value: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build label array matching ordered_filenames. Returns shape (n_samples,) of dtype int.\n",
    "    \"\"\"\n",
    "    Y = []\n",
    "    for fname in ordered_filenames:\n",
    "        # ensures we compare basenames\n",
    "        key = os.path.basename(fname)\n",
    "        if key in labels_dict:\n",
    "            Y.append(labels_dict[key])\n",
    "        else:\n",
    "            print(f\"Warning: No label found for {fname}, assigning {default_value}\")\n",
    "            Y.append(default_value)\n",
    "    return np.array(Y, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c867baa-be67-47fc-b762-59fcf6120a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = parse_destroyed_with_size_check(\"../EIDSeg_Dataset/data/train/train.xml\", min_coverage=0.05)\n",
    "labels_test  = parse_destroyed_with_size_check(\"../EIDSeg_Dataset/data/test/test.xml\",  min_coverage=0.05)\n",
    "\n",
    "X_train_org, ordered_filenames_train = load_and_resize_images(\"../EIDSeg_Dataset/data/train/images/default\", target_size=(64,64))\n",
    "X_test_org,  ordered_filenames_test  = load_and_resize_images(\"../EIDSeg_Dataset/data/test/images/default\",  target_size=(64,64))\n",
    "\n",
    "Y_train_org = build_label_array(ordered_filenames_train, labels_train)   # shape (n_train,)\n",
    "Y_test_org  = build_label_array(ordered_filenames_test,  labels_test)    # shape (n_test,)\n",
    "\n",
    "# quick sanity checks\n",
    "print(\"Train positive ratio:\", Y_train_org.mean(), \"n_train:\", Y_train_org.shape[0])\n",
    "print(\"Test  positive ratio:\", Y_test_org.mean(),  \"n_test:\",  Y_test_org.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
